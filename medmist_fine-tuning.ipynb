{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from datasets import Dataset as HFDataset, load_dataset, DatasetDict\n",
    "from typing import Optional, Tuple, Dict, Any\n",
    "from medmnist import BreastMNIST, RetinaMNIST\n",
    "from transformers import AutoModelForImageClassification, AutoImageProcessor, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, recall_score\n",
    "import random\n",
    "from imblearn.under_sampling import NearMiss\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedMNISTtoHF(Dataset):\n",
    "    def __init__(self, \n",
    "                 medmnist_dataset,\n",
    "                 transform: Optional[transforms.Compose] = None):\n",
    "        \"\"\"\n",
    "        Convert MedMNIST dataset to a format compatible with HuggingFace models\n",
    "        \n",
    "        Args:\n",
    "            medmnist_dataset: The original MedMNIST dataset\n",
    "            transform: Optional transforms to be applied to the images\n",
    "        \"\"\"\n",
    "        self.dataset = medmnist_dataset\n",
    "        self.transform = transform if transform else transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        img, label = self.dataset[idx]\n",
    "        \n",
    "        # Convert image to float32 tensor if it isn't already\n",
    "        #if not isinstance(img, torch.Tensor):\n",
    "            #img = self.transform(img)\n",
    "        \n",
    "        # Ensure image has correct number of channels (3 for most HF models)\n",
    "        #if img.shape[0] == 1:\n",
    "            #img = img.repeat(3, 1, 1)\n",
    "            \n",
    "        # Convert to HF expected format\n",
    "        return {\n",
    "            \"image\": img,\n",
    "            \"label\": torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def convert_medmnist_to_hf(medmnist_dataset, \n",
    "                          split: str = \"train\") -> HFDataset:\n",
    "    \"\"\"\n",
    "    Convert a MedMNIST dataset to HuggingFace dataset format\n",
    "    \n",
    "    Args:\n",
    "        medmnist_dataset: Original MedMNIST dataset\n",
    "        split: Dataset split name (\"train\", \"test\", or \"val\")\n",
    "    \n",
    "    Returns:\n",
    "        HuggingFace dataset\n",
    "    \"\"\"\n",
    "    # Create wrapper dataset\n",
    "    wrapper_dataset = MedMNISTtoHF(medmnist_dataset)\n",
    "    \n",
    "    # Convert to HF format\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(len(wrapper_dataset)):\n",
    "        sample = wrapper_dataset[i]\n",
    "        images.append(sample[\"image\"])\n",
    "        labels.append(sample[\"label\"].item())\n",
    "    \n",
    "    # Create HF dataset\n",
    "    hf_dataset = HFDataset.from_dict({\n",
    "        \"image\": images,\n",
    "        \"label\": labels\n",
    "    })\n",
    "    \n",
    "    return hf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BreastMNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\baiet\\.medmnist\\breastmnist_224.npz\n",
      "Using downloaded and verified file: C:\\Users\\baiet\\.medmnist\\breastmnist_224.npz\n",
      "Using downloaded and verified file: C:\\Users\\baiet\\.medmnist\\breastmnist_224.npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 367\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 78\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 156\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MedMNIST dataset\n",
    "train_dataset = BreastMNIST(split='train', download=True, size=224)\n",
    "val_dataset = BreastMNIST(split='val', download=True, size=224)\n",
    "test_dataset = BreastMNIST(split='test', download=True, size=224)\n",
    "\n",
    "hf_train_dataset = convert_medmnist_to_hf(train_dataset, split='train')\n",
    "hf_val_dataset = convert_medmnist_to_hf(val_dataset, split='val')\n",
    "hf_test_dataset = convert_medmnist_to_hf(test_dataset, split='test')\n",
    "\n",
    "# Balancing\n",
    "mj_class = Counter(hf_train_dataset['label']).most_common(1)[0][0]\n",
    "mn_class = abs(mj_class-1)\n",
    "data = hf_train_dataset['image']\n",
    "\n",
    "mask = [lb== mj_class for lb in hf_train_dataset['label']]\n",
    "X_majority = [img for img,flag in zip(data, mask) if flag]\n",
    "X_minority = [img for img,flag in zip(data, mask) if not flag]\n",
    "new_len_majority = len(X_minority) + int(0.5*len(X_minority))\n",
    "X_majority_resampled = resample(X_majority, \n",
    "                                replace=False,  # No replacement\n",
    "                                n_samples=new_len_majority,  # Match minority class size\n",
    "                                random_state=42)\n",
    "X_resampled = X_majority_resampled+ X_minority\n",
    "y_resampled = [mj_class]*new_len_majority+[mn_class]*len(X_minority)\n",
    "random.seed(42)\n",
    "random.shuffle(X_resampled)\n",
    "random.seed(42)\n",
    "random.shuffle(y_resampled)\n",
    "\n",
    "dict_train_blanced_dataset = {\n",
    "    \"image\": X_resampled,\n",
    "    \"label\": y_resampled\n",
    "}\n",
    " \n",
    "train_blanced_dataset = datasets.Dataset.from_dict(dict_train_blanced_dataset)\n",
    "\n",
    "dataset = DatasetDict({\"train\": train_blanced_dataset, \"validation\": hf_val_dataset, \"test\": hf_test_dataset})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BeitForImageClassification were not initialized from the model checkpoint at microsoft/beit-large-patch16-224-pt22k and are newly initialized: ['beit.pooler.layernorm.bias', 'beit.pooler.layernorm.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: ['beit.encoder.layer.23.lambda_1', 'beit.encoder.layer.23.lambda_2', 'beit.encoder.layer.23.attention.attention.query.weight', 'beit.encoder.layer.23.attention.attention.query.bias', 'beit.encoder.layer.23.attention.attention.key.weight', 'beit.encoder.layer.23.attention.attention.value.weight', 'beit.encoder.layer.23.attention.attention.value.bias', 'beit.encoder.layer.23.attention.output.dense.weight', 'beit.encoder.layer.23.attention.output.dense.bias', 'beit.encoder.layer.23.intermediate.dense.weight', 'beit.encoder.layer.23.intermediate.dense.bias', 'beit.encoder.layer.23.output.dense.weight', 'beit.encoder.layer.23.output.dense.bias', 'beit.encoder.layer.23.layernorm_before.weight', 'beit.encoder.layer.23.layernorm_before.bias', 'beit.encoder.layer.23.layernorm_after.weight', 'beit.encoder.layer.23.layernorm_after.bias', 'beit.pooler.layernorm.weight', 'beit.pooler.layernorm.bias', 'classifier.weight', 'classifier.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\baiet\\AppData\\Local\\Temp\\ipykernel_1584\\4135752904.py:52: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_beit_breastMNIST = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the BEiT-large model and image processor\n",
    "model_name = \"microsoft/beit-large-patch16-224-pt22k\"\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name, num_labels=2).to(device) \n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Freeze all layers except the classifier and the last transformer layer\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith(\"classifier\") \\\n",
    "        and not name.startswith(\"beit.pooler\")\\\n",
    "        and not name.startswith(\"beit.encoder.layer.23\") :#\\\n",
    "        #and not name.startswith(\"beit.encoder.layer.22\"):\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Verify which layers are trainable\n",
    "trainable_params = [name for name, param in model.named_parameters() if param.requires_grad]\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess_images(examples):\n",
    "    images = [processor(image.convert(\"RGB\"), return_tensors=\"pt\") for image in examples[\"image\"]]\n",
    "    pixel_values = torch.stack([image[\"pixel_values\"].squeeze() for image in images])\n",
    "    labels = torch.tensor(examples[\"label\"])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "# Preprocess the dataset\n",
    "train_dataset = dataset[\"train\"].with_transform(preprocess_images)\n",
    "validation_dataset = dataset[\"validation\"].with_transform(preprocess_images)\n",
    "test_dataset = dataset[\"test\"].with_transform(preprocess_images)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./beit_breastMNIST\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer_beit_breastMNIST = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 01:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.566800</td>\n",
       "      <td>0.498798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.565300</td>\n",
       "      <td>0.410432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.429800</td>\n",
       "      <td>0.386300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>0.433248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.145500</td>\n",
       "      <td>0.448869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'eval_loss': 0.36107274889945984, 'eval_runtime': 4.4894, 'eval_samples_per_second': 34.748, 'eval_steps_per_second': 4.455, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer_beit_breastMNIST.train()\n",
    "\n",
    "# Save the model and processor\n",
    "model.save_pretrained(\"./beit_breastMNIST\")\n",
    "processor.save_pretrained(\"./beit_breastMNIST\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer_beit_breastMNIST.evaluate(test_dataset)\n",
    "print(f\"Test Results: {test_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8718\n",
      "Precision (weighted): 0.8690\n",
      "Recall (weighted): 0.8718\n",
      "F1-Score (weighted): 0.8697\n",
      "Specificity: 0.7143\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer_beit_breastMNIST.predict(test_dataset)\n",
    "pred_labels = predictions.predictions.argmax(axis=1)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "# Calculate additional metrics\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
    "specificity = recall_score(true_labels, pred_labels, pos_label=0)\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (weighted): {precision:.4f}\")\n",
    "print(f\"Recall (weighted): {recall:.4f}\")\n",
    "print(f\"F1-Score (weighted): {f1:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 71.43%\n",
      "Class 1: 92.98%\n"
     ]
    }
   ],
   "source": [
    "# Unique classes\n",
    "classes = np.unique(true_labels)\n",
    "\n",
    "# Per-class accuracy\n",
    "per_class_accuracy = {}\n",
    "for c in classes:\n",
    "    # Get indices of samples belonging to class c\n",
    "    indices = true_labels == c\n",
    "\n",
    "    # Count correct predictions for class c\n",
    "    correct = np.sum(pred_labels[indices] == true_labels[indices])\n",
    "\n",
    "    # Total samples in class c\n",
    "    total = np.sum(indices)\n",
    "\n",
    "    # Accuracy for class c\n",
    "    per_class_accuracy[c] = (correct / total) * 100\n",
    "\n",
    "# Print per-class accuracy\n",
    "for cls, acc in per_class_accuracy.items():\n",
    "    print(f\"Class {cls}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([2, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: ['resnet.embedder.embedder.convolution.weight', 'resnet.embedder.embedder.normalization.weight', 'resnet.embedder.embedder.normalization.bias', 'resnet.encoder.stages.0.layers.0.shortcut.convolution.weight', 'resnet.encoder.stages.0.layers.0.shortcut.normalization.weight', 'resnet.encoder.stages.0.layers.0.shortcut.normalization.bias', 'resnet.encoder.stages.0.layers.0.layer.0.convolution.weight', 'resnet.encoder.stages.0.layers.0.layer.0.normalization.weight', 'resnet.encoder.stages.0.layers.0.layer.0.normalization.bias', 'resnet.encoder.stages.0.layers.0.layer.1.convolution.weight', 'resnet.encoder.stages.0.layers.0.layer.1.normalization.weight', 'resnet.encoder.stages.0.layers.0.layer.1.normalization.bias', 'resnet.encoder.stages.0.layers.0.layer.2.convolution.weight', 'resnet.encoder.stages.0.layers.0.layer.2.normalization.weight', 'resnet.encoder.stages.0.layers.0.layer.2.normalization.bias', 'resnet.encoder.stages.0.layers.1.layer.0.convolution.weight', 'resnet.encoder.stages.0.layers.1.layer.0.normalization.weight', 'resnet.encoder.stages.0.layers.1.layer.0.normalization.bias', 'resnet.encoder.stages.0.layers.1.layer.1.convolution.weight', 'resnet.encoder.stages.0.layers.1.layer.1.normalization.weight', 'resnet.encoder.stages.0.layers.1.layer.1.normalization.bias', 'resnet.encoder.stages.0.layers.1.layer.2.convolution.weight', 'resnet.encoder.stages.0.layers.1.layer.2.normalization.weight', 'resnet.encoder.stages.0.layers.1.layer.2.normalization.bias', 'resnet.encoder.stages.0.layers.2.layer.0.convolution.weight', 'resnet.encoder.stages.0.layers.2.layer.0.normalization.weight', 'resnet.encoder.stages.0.layers.2.layer.0.normalization.bias', 'resnet.encoder.stages.0.layers.2.layer.1.convolution.weight', 'resnet.encoder.stages.0.layers.2.layer.1.normalization.weight', 'resnet.encoder.stages.0.layers.2.layer.1.normalization.bias', 'resnet.encoder.stages.0.layers.2.layer.2.convolution.weight', 'resnet.encoder.stages.0.layers.2.layer.2.normalization.weight', 'resnet.encoder.stages.0.layers.2.layer.2.normalization.bias', 'resnet.encoder.stages.1.layers.0.shortcut.convolution.weight', 'resnet.encoder.stages.1.layers.0.shortcut.normalization.weight', 'resnet.encoder.stages.1.layers.0.shortcut.normalization.bias', 'resnet.encoder.stages.1.layers.0.layer.0.convolution.weight', 'resnet.encoder.stages.1.layers.0.layer.0.normalization.weight', 'resnet.encoder.stages.1.layers.0.layer.0.normalization.bias', 'resnet.encoder.stages.1.layers.0.layer.1.convolution.weight', 'resnet.encoder.stages.1.layers.0.layer.1.normalization.weight', 'resnet.encoder.stages.1.layers.0.layer.1.normalization.bias', 'resnet.encoder.stages.1.layers.0.layer.2.convolution.weight', 'resnet.encoder.stages.1.layers.0.layer.2.normalization.weight', 'resnet.encoder.stages.1.layers.0.layer.2.normalization.bias', 'resnet.encoder.stages.1.layers.1.layer.0.convolution.weight', 'resnet.encoder.stages.1.layers.1.layer.0.normalization.weight', 'resnet.encoder.stages.1.layers.1.layer.0.normalization.bias', 'resnet.encoder.stages.1.layers.1.layer.1.convolution.weight', 'resnet.encoder.stages.1.layers.1.layer.1.normalization.weight', 'resnet.encoder.stages.1.layers.1.layer.1.normalization.bias', 'resnet.encoder.stages.1.layers.1.layer.2.convolution.weight', 'resnet.encoder.stages.1.layers.1.layer.2.normalization.weight', 'resnet.encoder.stages.1.layers.1.layer.2.normalization.bias', 'resnet.encoder.stages.1.layers.2.layer.0.convolution.weight', 'resnet.encoder.stages.1.layers.2.layer.0.normalization.weight', 'resnet.encoder.stages.1.layers.2.layer.0.normalization.bias', 'resnet.encoder.stages.1.layers.2.layer.1.convolution.weight', 'resnet.encoder.stages.1.layers.2.layer.1.normalization.weight', 'resnet.encoder.stages.1.layers.2.layer.1.normalization.bias', 'resnet.encoder.stages.1.layers.2.layer.2.convolution.weight', 'resnet.encoder.stages.1.layers.2.layer.2.normalization.weight', 'resnet.encoder.stages.1.layers.2.layer.2.normalization.bias', 'resnet.encoder.stages.1.layers.3.layer.0.convolution.weight', 'resnet.encoder.stages.1.layers.3.layer.0.normalization.weight', 'resnet.encoder.stages.1.layers.3.layer.0.normalization.bias', 'resnet.encoder.stages.1.layers.3.layer.1.convolution.weight', 'resnet.encoder.stages.1.layers.3.layer.1.normalization.weight', 'resnet.encoder.stages.1.layers.3.layer.1.normalization.bias', 'resnet.encoder.stages.1.layers.3.layer.2.convolution.weight', 'resnet.encoder.stages.1.layers.3.layer.2.normalization.weight', 'resnet.encoder.stages.1.layers.3.layer.2.normalization.bias', 'resnet.encoder.stages.2.layers.0.shortcut.convolution.weight', 'resnet.encoder.stages.2.layers.0.shortcut.normalization.weight', 'resnet.encoder.stages.2.layers.0.shortcut.normalization.bias', 'resnet.encoder.stages.2.layers.0.layer.0.convolution.weight', 'resnet.encoder.stages.2.layers.0.layer.0.normalization.weight', 'resnet.encoder.stages.2.layers.0.layer.0.normalization.bias', 'resnet.encoder.stages.2.layers.0.layer.1.convolution.weight', 'resnet.encoder.stages.2.layers.0.layer.1.normalization.weight', 'resnet.encoder.stages.2.layers.0.layer.1.normalization.bias', 'resnet.encoder.stages.2.layers.0.layer.2.convolution.weight', 'resnet.encoder.stages.2.layers.0.layer.2.normalization.weight', 'resnet.encoder.stages.2.layers.0.layer.2.normalization.bias', 'resnet.encoder.stages.2.layers.1.layer.0.convolution.weight', 'resnet.encoder.stages.2.layers.1.layer.0.normalization.weight', 'resnet.encoder.stages.2.layers.1.layer.0.normalization.bias', 'resnet.encoder.stages.2.layers.1.layer.1.convolution.weight', 'resnet.encoder.stages.2.layers.1.layer.1.normalization.weight', 'resnet.encoder.stages.2.layers.1.layer.1.normalization.bias', 'resnet.encoder.stages.2.layers.1.layer.2.convolution.weight', 'resnet.encoder.stages.2.layers.1.layer.2.normalization.weight', 'resnet.encoder.stages.2.layers.1.layer.2.normalization.bias', 'resnet.encoder.stages.2.layers.2.layer.0.convolution.weight', 'resnet.encoder.stages.2.layers.2.layer.0.normalization.weight', 'resnet.encoder.stages.2.layers.2.layer.0.normalization.bias', 'resnet.encoder.stages.2.layers.2.layer.1.convolution.weight', 'resnet.encoder.stages.2.layers.2.layer.1.normalization.weight', 'resnet.encoder.stages.2.layers.2.layer.1.normalization.bias', 'resnet.encoder.stages.2.layers.2.layer.2.convolution.weight', 'resnet.encoder.stages.2.layers.2.layer.2.normalization.weight', 'resnet.encoder.stages.2.layers.2.layer.2.normalization.bias', 'resnet.encoder.stages.2.layers.3.layer.0.convolution.weight', 'resnet.encoder.stages.2.layers.3.layer.0.normalization.weight', 'resnet.encoder.stages.2.layers.3.layer.0.normalization.bias', 'resnet.encoder.stages.2.layers.3.layer.1.convolution.weight', 'resnet.encoder.stages.2.layers.3.layer.1.normalization.weight', 'resnet.encoder.stages.2.layers.3.layer.1.normalization.bias', 'resnet.encoder.stages.2.layers.3.layer.2.convolution.weight', 'resnet.encoder.stages.2.layers.3.layer.2.normalization.weight', 'resnet.encoder.stages.2.layers.3.layer.2.normalization.bias', 'resnet.encoder.stages.2.layers.4.layer.0.convolution.weight', 'resnet.encoder.stages.2.layers.4.layer.0.normalization.weight', 'resnet.encoder.stages.2.layers.4.layer.0.normalization.bias', 'resnet.encoder.stages.2.layers.4.layer.1.convolution.weight', 'resnet.encoder.stages.2.layers.4.layer.1.normalization.weight', 'resnet.encoder.stages.2.layers.4.layer.1.normalization.bias', 'resnet.encoder.stages.2.layers.4.layer.2.convolution.weight', 'resnet.encoder.stages.2.layers.4.layer.2.normalization.weight', 'resnet.encoder.stages.2.layers.4.layer.2.normalization.bias', 'resnet.encoder.stages.2.layers.5.layer.0.convolution.weight', 'resnet.encoder.stages.2.layers.5.layer.0.normalization.weight', 'resnet.encoder.stages.2.layers.5.layer.0.normalization.bias', 'resnet.encoder.stages.2.layers.5.layer.1.convolution.weight', 'resnet.encoder.stages.2.layers.5.layer.1.normalization.weight', 'resnet.encoder.stages.2.layers.5.layer.1.normalization.bias', 'resnet.encoder.stages.2.layers.5.layer.2.convolution.weight', 'resnet.encoder.stages.2.layers.5.layer.2.normalization.weight', 'resnet.encoder.stages.2.layers.5.layer.2.normalization.bias', 'resnet.encoder.stages.3.layers.0.shortcut.convolution.weight', 'resnet.encoder.stages.3.layers.0.shortcut.normalization.weight', 'resnet.encoder.stages.3.layers.0.shortcut.normalization.bias', 'resnet.encoder.stages.3.layers.0.layer.0.convolution.weight', 'resnet.encoder.stages.3.layers.0.layer.0.normalization.weight', 'resnet.encoder.stages.3.layers.0.layer.0.normalization.bias', 'resnet.encoder.stages.3.layers.0.layer.1.convolution.weight', 'resnet.encoder.stages.3.layers.0.layer.1.normalization.weight', 'resnet.encoder.stages.3.layers.0.layer.1.normalization.bias', 'resnet.encoder.stages.3.layers.0.layer.2.convolution.weight', 'resnet.encoder.stages.3.layers.0.layer.2.normalization.weight', 'resnet.encoder.stages.3.layers.0.layer.2.normalization.bias', 'resnet.encoder.stages.3.layers.1.layer.0.convolution.weight', 'resnet.encoder.stages.3.layers.1.layer.0.normalization.weight', 'resnet.encoder.stages.3.layers.1.layer.0.normalization.bias', 'resnet.encoder.stages.3.layers.1.layer.1.convolution.weight', 'resnet.encoder.stages.3.layers.1.layer.1.normalization.weight', 'resnet.encoder.stages.3.layers.1.layer.1.normalization.bias', 'resnet.encoder.stages.3.layers.1.layer.2.convolution.weight', 'resnet.encoder.stages.3.layers.1.layer.2.normalization.weight', 'resnet.encoder.stages.3.layers.1.layer.2.normalization.bias', 'resnet.encoder.stages.3.layers.2.layer.0.convolution.weight', 'resnet.encoder.stages.3.layers.2.layer.0.normalization.weight', 'resnet.encoder.stages.3.layers.2.layer.0.normalization.bias', 'resnet.encoder.stages.3.layers.2.layer.1.convolution.weight', 'resnet.encoder.stages.3.layers.2.layer.1.normalization.weight', 'resnet.encoder.stages.3.layers.2.layer.1.normalization.bias', 'resnet.encoder.stages.3.layers.2.layer.2.convolution.weight', 'resnet.encoder.stages.3.layers.2.layer.2.normalization.weight', 'resnet.encoder.stages.3.layers.2.layer.2.normalization.bias', 'classifier.1.weight', 'classifier.1.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiet\\AppData\\Local\\Temp\\ipykernel_1584\\1125069783.py:51: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_resnet_breastMNIST = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the BEiT-large model and image processor\n",
    "model_name = \"microsoft/resnet-50\"\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True).to(device)\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Freeze all layers except the classifier and the last transformer layer\n",
    "'''\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith(\"classifier\") \\\n",
    "        and not name.startswith(\"resnet.encoder.stages.3.layers.2\")\\\n",
    "        and not name.startswith(\"resnet.encoder.stages.3.layers.1\"):\n",
    "        param.requires_grad = False\n",
    "'''\n",
    "# Verify which layers are trainable\n",
    "trainable_params = [name for name, param in model.named_parameters() if param.requires_grad]\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess_images(examples):\n",
    "    images = [processor(image.convert(\"RGB\"), return_tensors=\"pt\") for image in examples[\"image\"]]\n",
    "    pixel_values = torch.stack([image[\"pixel_values\"].squeeze() for image in images])\n",
    "    labels = torch.tensor(examples[\"label\"])\n",
    "    return {\"pixel_values\": pixel_values, \"label\": labels}\n",
    "\n",
    "# Preprocess the dataset\n",
    "train_dataset = dataset[\"train\"].with_transform(preprocess_images)\n",
    "validation_dataset = dataset[\"validation\"].with_transform(preprocess_images)\n",
    "test_dataset = dataset[\"test\"].with_transform(preprocess_images)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./resnet_breastMNIST\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer_resnet_breastMNIST = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 05:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.632800</td>\n",
       "      <td>0.625107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.586400</td>\n",
       "      <td>0.562325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.541800</td>\n",
       "      <td>0.719630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.427200</td>\n",
       "      <td>0.537232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.330300</td>\n",
       "      <td>0.498492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'eval_loss': 0.42436087131500244, 'eval_runtime': 6.3165, 'eval_samples_per_second': 24.697, 'eval_steps_per_second': 3.166, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer_resnet_breastMNIST.train()\n",
    "\n",
    "# Save the model and processor\n",
    "model.save_pretrained(\"./resnet_breastMNIST\")\n",
    "processor.save_pretrained(\"./resnet_breastMNIST\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer_resnet_breastMNIST.evaluate(test_dataset)\n",
    "print(f\"Test Results: {test_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8269\n",
      "Precision (weighted): 0.8268\n",
      "Recall (weighted): 0.8269\n",
      "F1-Score (weighted): 0.8083\n",
      "Specificity: 0.4524\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer_resnet_breastMNIST.predict(test_dataset)\n",
    "pred_labels = predictions.predictions.argmax(axis=1)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "# Calculate additional metrics\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
    "specificity = recall_score(true_labels, pred_labels, pos_label=0)\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (weighted): {precision:.4f}\")\n",
    "print(f\"Recall (weighted): {recall:.4f}\")\n",
    "print(f\"F1-Score (weighted): {f1:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 45.24%\n",
      "Class 1: 96.49%\n"
     ]
    }
   ],
   "source": [
    "# Unique classes\n",
    "classes = np.unique(true_labels)\n",
    "\n",
    "# Per-class accuracy\n",
    "per_class_accuracy = {}\n",
    "for c in classes:\n",
    "    # Get indices of samples belonging to class c\n",
    "    indices = true_labels == c\n",
    "\n",
    "    # Count correct predictions for class c\n",
    "    correct = np.sum(pred_labels[indices] == true_labels[indices])\n",
    "\n",
    "    # Total samples in class c\n",
    "    total = np.sum(indices)\n",
    "\n",
    "    # Accuracy for class c\n",
    "    per_class_accuracy[c] = (correct / total) * 100\n",
    "\n",
    "# Print per-class accuracy\n",
    "for cls, acc in per_class_accuracy.items():\n",
    "    print(f\"Class {cls}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retina MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\baiet\\.medmnist\\retinamnist_224.npz\n",
      "Using downloaded and verified file: C:\\Users\\baiet\\.medmnist\\retinamnist_224.npz\n",
      "Using downloaded and verified file: C:\\Users\\baiet\\.medmnist\\retinamnist_224.npz\n"
     ]
    }
   ],
   "source": [
    "# Load MedMNIST dataset\n",
    "train_dataset = RetinaMNIST(split='train', download=True, size=224)\n",
    "val_dataset = RetinaMNIST(split='val', download=True, size=224)\n",
    "test_dataset = RetinaMNIST(split='test', download=True, size=224)\n",
    "\n",
    "hf_train_dataset = convert_medmnist_to_hf(train_dataset, split='train')\n",
    "hf_val_dataset = convert_medmnist_to_hf(val_dataset, split='val')\n",
    "hf_test_dataset = convert_medmnist_to_hf(test_dataset, split='test')\n",
    "\n",
    "dataset = DatasetDict({\"train\": hf_train_dataset, \"validation\": hf_val_dataset, \"test\": hf_test_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BeitForImageClassification were not initialized from the model checkpoint at microsoft/beit-large-patch16-224-pt22k and are newly initialized: ['beit.pooler.layernorm.bias', 'beit.pooler.layernorm.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: ['beit.encoder.layer.22.lambda_1', 'beit.encoder.layer.22.lambda_2', 'beit.encoder.layer.22.attention.attention.query.weight', 'beit.encoder.layer.22.attention.attention.query.bias', 'beit.encoder.layer.22.attention.attention.key.weight', 'beit.encoder.layer.22.attention.attention.value.weight', 'beit.encoder.layer.22.attention.attention.value.bias', 'beit.encoder.layer.22.attention.output.dense.weight', 'beit.encoder.layer.22.attention.output.dense.bias', 'beit.encoder.layer.22.intermediate.dense.weight', 'beit.encoder.layer.22.intermediate.dense.bias', 'beit.encoder.layer.22.output.dense.weight', 'beit.encoder.layer.22.output.dense.bias', 'beit.encoder.layer.22.layernorm_before.weight', 'beit.encoder.layer.22.layernorm_before.bias', 'beit.encoder.layer.22.layernorm_after.weight', 'beit.encoder.layer.22.layernorm_after.bias', 'beit.encoder.layer.23.lambda_1', 'beit.encoder.layer.23.lambda_2', 'beit.encoder.layer.23.attention.attention.query.weight', 'beit.encoder.layer.23.attention.attention.query.bias', 'beit.encoder.layer.23.attention.attention.key.weight', 'beit.encoder.layer.23.attention.attention.value.weight', 'beit.encoder.layer.23.attention.attention.value.bias', 'beit.encoder.layer.23.attention.output.dense.weight', 'beit.encoder.layer.23.attention.output.dense.bias', 'beit.encoder.layer.23.intermediate.dense.weight', 'beit.encoder.layer.23.intermediate.dense.bias', 'beit.encoder.layer.23.output.dense.weight', 'beit.encoder.layer.23.output.dense.bias', 'beit.encoder.layer.23.layernorm_before.weight', 'beit.encoder.layer.23.layernorm_before.bias', 'beit.encoder.layer.23.layernorm_after.weight', 'beit.encoder.layer.23.layernorm_after.bias', 'beit.pooler.layernorm.weight', 'beit.pooler.layernorm.bias', 'classifier.weight', 'classifier.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\baiet\\AppData\\Local\\Temp\\ipykernel_1584\\3857256845.py:52: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_beit_retinaMNIST = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the BEiT-large model and image processor\n",
    "model_name = \"microsoft/beit-large-patch16-224-pt22k\"\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name, num_labels=5).to(device) \n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Freeze all layers except the classifier and the last transformer layer\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith(\"classifier\") \\\n",
    "        and not name.startswith(\"beit.pooler\")\\\n",
    "        and not name.startswith(\"beit.encoder.layer.23\") \\\n",
    "        and not name.startswith(\"beit.encoder.layer.22\"):\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Verify which layers are trainable\n",
    "trainable_params = [name for name, param in model.named_parameters() if param.requires_grad]\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess_images(examples):\n",
    "    images = [processor(image.convert(\"RGB\"), return_tensors=\"pt\") for image in examples[\"image\"]]\n",
    "    pixel_values = torch.stack([image[\"pixel_values\"].squeeze() for image in images])\n",
    "    labels = torch.tensor(examples[\"label\"])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "# Preprocess the dataset\n",
    "train_dataset = dataset[\"train\"].with_transform(preprocess_images)\n",
    "validation_dataset = dataset[\"validation\"].with_transform(preprocess_images)\n",
    "test_dataset = dataset[\"test\"].with_transform(preprocess_images)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./beit_retinaMNIST\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.1,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer_beit_retinaMNIST = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 03:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.217500</td>\n",
       "      <td>1.056499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.249700</td>\n",
       "      <td>1.063681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.189300</td>\n",
       "      <td>0.905668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.863200</td>\n",
       "      <td>0.994372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.661300</td>\n",
       "      <td>1.032848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'eval_loss': 1.0201350450515747, 'eval_runtime': 11.2566, 'eval_samples_per_second': 35.535, 'eval_steps_per_second': 4.442, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer_beit_retinaMNIST.train()\n",
    "\n",
    "# Save the model and processor\n",
    "model.save_pretrained(\"./beit_retinaMNIST\")\n",
    "processor.save_pretrained(\"./beit_retinaMNIST\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer_beit_retinaMNIST.evaluate(test_dataset)\n",
    "print(f\"Test Results: {test_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6200\n",
      "Precision (weighted): 0.6308\n",
      "Recall (weighted): 0.6200\n",
      "F1-Score (weighted): 0.6143\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer_beit_retinaMNIST.predict(test_dataset)\n",
    "pred_labels = predictions.predictions.argmax(axis=1)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "# Calculate additional metrics\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
    "#specificity = recall_score(true_labels, pred_labels, pos_label=0)\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (weighted): {precision:.4f}\")\n",
    "print(f\"Recall (weighted): {recall:.4f}\")\n",
    "print(f\"F1-Score (weighted): {f1:.4f}\")\n",
    "#print(f\"Specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 78.16%\n",
      "Class 1: 30.43%\n",
      "Class 2: 59.78%\n",
      "Class 3: 58.82%\n",
      "Class 4: 15.00%\n"
     ]
    }
   ],
   "source": [
    "# Unique classes\n",
    "classes = np.unique(true_labels)\n",
    "\n",
    "# Per-class accuracy\n",
    "per_class_accuracy = {}\n",
    "for c in classes:\n",
    "    # Get indices of samples belonging to class c\n",
    "    indices = true_labels == c\n",
    "\n",
    "    # Count correct predictions for class c\n",
    "    correct = np.sum(pred_labels[indices] == true_labels[indices])\n",
    "\n",
    "    # Total samples in class c\n",
    "    total = np.sum(indices)\n",
    "\n",
    "    # Accuracy for class c\n",
    "    per_class_accuracy[c] = (correct / total) * 100\n",
    "\n",
    "# Print per-class accuracy\n",
    "for cls, acc in per_class_accuracy.items():\n",
    "    print(f\"Class {cls}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([5, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: ['resnet.encoder.stages.3.layers.2.layer.0.convolution.weight', 'resnet.encoder.stages.3.layers.2.layer.0.normalization.weight', 'resnet.encoder.stages.3.layers.2.layer.0.normalization.bias', 'resnet.encoder.stages.3.layers.2.layer.1.convolution.weight', 'resnet.encoder.stages.3.layers.2.layer.1.normalization.weight', 'resnet.encoder.stages.3.layers.2.layer.1.normalization.bias', 'resnet.encoder.stages.3.layers.2.layer.2.convolution.weight', 'resnet.encoder.stages.3.layers.2.layer.2.normalization.weight', 'resnet.encoder.stages.3.layers.2.layer.2.normalization.bias', 'classifier.1.weight', 'classifier.1.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\baiet\\AppData\\Local\\Temp\\ipykernel_1584\\3689944832.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_resnet_retinaMNIST = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the BEiT-large model and image processor\n",
    "model_name = \"microsoft/resnet-50\"\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name, num_labels=5, ignore_mismatched_sizes=True).to(device)\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Freeze all layers except the classifier and the last transformer layer\n",
    "for name, param in model.named_parameters():\n",
    "    if not name.startswith(\"classifier\") and not name.startswith(\"resnet.encoder.stages.3.layers.2\"):\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Verify which layers are trainable\n",
    "trainable_params = [name for name, param in model.named_parameters() if param.requires_grad]\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess_images(examples):\n",
    "    images = [processor(image.convert(\"RGB\"), return_tensors=\"pt\") for image in examples[\"image\"]]\n",
    "    pixel_values = torch.stack([image[\"pixel_values\"].squeeze() for image in images])\n",
    "    labels = torch.tensor(examples[\"label\"])\n",
    "    return {\"pixel_values\": pixel_values, \"label\": labels}\n",
    "\n",
    "# Preprocess the dataset\n",
    "train_dataset = dataset[\"train\"].with_transform(preprocess_images)\n",
    "validation_dataset = dataset[\"validation\"].with_transform(preprocess_images)\n",
    "test_dataset = dataset[\"test\"].with_transform(preprocess_images)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./resnet_retinaMNIST\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer_resnet_retinaMNIST = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 00:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.158900</td>\n",
       "      <td>1.244556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.188800</td>\n",
       "      <td>1.146783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.109000</td>\n",
       "      <td>1.132084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.078300</td>\n",
       "      <td>1.108217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.090300</td>\n",
       "      <td>1.112605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'eval_loss': 1.1273815631866455, 'eval_runtime': 2.3279, 'eval_samples_per_second': 171.829, 'eval_steps_per_second': 21.479, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer_resnet_retinaMNIST.train()\n",
    "\n",
    "# Save the model and processor\n",
    "model.save_pretrained(\"./resnet_retinaMNIST\")\n",
    "processor.save_pretrained(\"./resnet_retinaMNIST\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer_resnet_retinaMNIST.evaluate(test_dataset)\n",
    "print(f\"Test Results: {test_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5550\n",
      "Precision (weighted): 0.4491\n",
      "Recall (weighted): 0.5550\n",
      "F1-Score (weighted): 0.4697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baiet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer_resnet_retinaMNIST.predict(test_dataset)\n",
    "pred_labels = predictions.predictions.argmax(axis=1)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "# Calculate additional metrics\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
    "#specificity = recall_score(true_labels, pred_labels, pos_label=0)\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (weighted): {precision:.4f}\")\n",
    "print(f\"Recall (weighted): {recall:.4f}\")\n",
    "print(f\"F1-Score (weighted): {f1:.4f}\")\n",
    "#print(f\"Specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 95.98%\n",
      "Class 1: 0.00%\n",
      "Class 2: 21.74%\n",
      "Class 3: 51.47%\n",
      "Class 4: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Unique classes\n",
    "classes = np.unique(true_labels)\n",
    "\n",
    "# Per-class accuracy\n",
    "per_class_accuracy = {}\n",
    "for c in classes:\n",
    "    # Get indices of samples belonging to class c\n",
    "    indices = true_labels == c\n",
    "\n",
    "    # Count correct predictions for class c\n",
    "    correct = np.sum(pred_labels[indices] == true_labels[indices])\n",
    "\n",
    "    # Total samples in class c\n",
    "    total = np.sum(indices)\n",
    "\n",
    "    # Accuracy for class c\n",
    "    per_class_accuracy[c] = (correct / total) * 100\n",
    "\n",
    "# Print per-class accuracy\n",
    "for cls, acc in per_class_accuracy.items():\n",
    "    print(f\"Class {cls}: {acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
